# llm-labeling-study-2025
A comparative study of data annotation quality using Large Language Models (LLMs) versus human-labeled datasets. Experiments cover multiple NLP tasks (sentiment analysis, named entity recognition, toxicity classification, and natural language inference) using IMDb, CoNLL-2003, Jigsaw, and SNLI datasets.
